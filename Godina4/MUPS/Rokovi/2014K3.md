**1. [15] Objasniti o čemu mora da se vodi računa pri razvoju paralelnog softvera da bi se smanjio overhead pri održanju koherencije i poboljšale performanse.**

- Treba komunicirati što manje sa procesorima koji su udaljeni
- Treba paziti kojim memorijskim lokacijama se pristupa, i pristupati samo onim kojima je stvarno potrebno

**2. [10] Objasniti zašto primena isključivo invalidacione ili ažurirajuće strategije najčešće nije optimalno rešenje. Objasniti kako se to prevazilazi.**

Ako se koristi samo invalidaciona strategija, to možda nije dobro jer možda postoje blokovi koje deli jako puno procesora, a upisuju se jako retko. Taj upis bi ih onda invalidirao svima koji ih koriste. Sa druge strane, ako se koristi samo ažurirajuća strategija, možda postoje blokovi koje su neki procesori davno koristili, a sad više ih ne koriste, a neki procesori su počeli da jako često upisuju u te blokove. U tom slučaju se vrše nepotrebna ažuriranja blokova u procesorima koji ih više ne koriste. Rešenje je da se koristi adaptivna strategija, koja će da počne ažurirajućim protokolom, pa ako se previše puta u kratkom vremenskom roku desi ažuriranje, da pređe na invalidacioni protokol.

**3. [20] Šta se postiže primenom “_cache-based_” protokola? Objasniti organizaciju kataloga i izračunati njegovu veličinu ako je _m_ – veličina memorije, _c_ – veličina keš memorije po procesoru, _b_ - veličina bloka i _n_ – broj procesora. Precizno opisati šta se dešava kod _read miss_-a i _write hit_-a.**

Postiže se to da katalog zauzima manje mesta, i invalidacije su decentralizovane, ne vrši ih više matični čvor.

Katalog se organizuje tako što matični čvor ima samo pokazivač na početak liste čvorova koji sadrže njegov blok u svojim keševima, a svaki čvor ima pokazivač na sledeći (i možda prethodni, ako je u pitanju dvostruko ulančana lista). Takođe, svaki čvor pamti i da li je _dirty_ kopija. Za to mu je dovoljan još jedan bit.

Veličina (u bitima):
- Katalog za pokazivače na početke listi: _m_/_b_*_log(n)_
- Katalog za pokazivače na sledeće elemente: _c_/_b_*(_log(n)_ + 1)

Akcije:
- Read miss: Procesor šalje poruku matičnom čvoru, matični čvor ga dodaje u listu. Postoje dve situacije:
    - Nijedan čvor nije držao trenutni blok sa aktivnim _dirty_ bitom - u ovom slučaju samo matični čvor šalje svoje podatke čvoru koji ih traži.
    - Neki čvor je držao trenutni blok sa aktivnim _dirty_ bitom - u ovom slučaju matični čvor tom čvoru šalje poruku, taj čvor odgovara i matičnom čvoru i čvoru koji je tražio podatke, i briše svoj dirty bit.
- Write hit: Postoje dve situacije u zavisnosti od toga da li se radi write update ili write invalidate strategija:
    - Write update: Ukoliko postoji još kopija, procesor prolazi kroz celu listu, i šalje svima poruku o promeni vrednosti. Ukoliko ne postoji, samo setuje svoj _dirty_ bit
    - Write invalidate: Ukoliko postoji još kopija, procesor prolazi kroz celu listu, i invalidira sve ostale kopije. One se izbacuju iz liste. Posle toga, setuje svoj _dirty_ bit

**4. [15] a) Definisati pojam inkluzije u keš hijerarhiji. Objasniti šta se dobija primenom inkluzije. b) U slučaju da se održava inkluzija, objasniti koje sve se transakcije i kako obavljaju između dva nivoa keš memorije**

a) Inkluzija predstavlja pojavu kada se u nižim nivoima keša obavezno nalazi podskup podataka sa višeg nivoa. Inkluzijom se dobija manja složenost algoritma koherencije, jer samo najviši nivo mora da osluškuje promene na ostalim procesorima

b) U slučaju da se koristi WT politika, nije potrebna sledeća akcija, a u slučaju da se koristi WB politika, potrebna je: Kada L2 keš snoopuje zahtev za nekim podatkom koji se nalazi u L1 kešu, i dirty je (u L2 je ovo stanje dirty-invalid), javi L1 kešu da treba da flush-uje taj blok, kako bi ga L2 keš poslao na magistralu. U slučaju da se desi RH ili WH u L1 kešu, i u slučaju da je LRU algoritam zamene, podatak o tome da se desio hit se mora propagirati do L2 keša, kako bi taj podatak bio najskorije korišćen i u tom kešu.

**5. [15] Šta predstavlja _loop unrolling_ tehnika za optimizaciju petlji? Na primeru `reductionSum` jezgra pokazati kako ona može da doprinese poboljšanju performansi koda koji se izvršava na grafičkom procesoru.**

```C
__global__ void reductionSum (int* devA, int* blockResults, int n) {
    extern __shared__ int sharedData[];
    unsigned int tid = threadIdx.x;
    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) sharedData[tid] = devA[i];
    else sharedData[tid] = 0;
    __syncthreads();
    for (unsigned int s = blockDim.x/2; s > 0; s >>= 1) {
        if (tid < s) {
            sharedData[tid] += sharedData[tid + s];
        }
        __syncthreads();
    }
    if (tid == 0) blockResults[blockIdx.x] = sharedData[0];
}
```

**Rešenje:**

_Loop unrolling_ predstavlja optimizaciju kod petlji čije su iteracije izuzetno kratke - u ovakvim petljama odnos korisnog rada i overheada skokova na početak iteracije nije dobar, tako da se više malih iteracija pakuje unutar jedne velike, posle koje se vrši skok na početak petlje. _Loop peeling_ je optimizacija koja je u ovom kodu poželjna. To podrazumeva "ljuštenje" nekoliko iteracija petlje, i njihovo izvršavanje pre ili posle stvarne petlje. U ovom konkretnom slučaju, poslednjih par iteracija je moguće izvršiti posle petlje

```C
__global__ void reductionSum (int* devA, int* blockResults, int n) {
    extern __shared__ int sharedData[];
    unsigned int tid = threadIdx.x;
    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) sharedData[tid] = devA[i];
    else sharedData[tid] = 0;
    __syncthreads();
    for (unsigned int s = blockDim.x/2; s > 32; s >>= 1) {
        if (tid < s) {
            sharedData[tid] += sharedData[tid + s];
        }
        __syncthreads();
    }
    // ...
    if (tid < 32 && n >= 64) sharedData[tid] += sharedData[tid + 32];
    if (tid < 16 && n >= 32) sharedData[tid] += sharedData[tid + 16];
    if (tid <  8 && n >= 16) sharedData[tid] += sharedData[tid +  8];
    if (tid <  4 && n >=  8) sharedData[tid] += sharedData[tid +  4];
    if (tid <  2 && n >=  4) sharedData[tid] += sharedData[tid +  2];
    if (tid <  1 && n >=  2) sharedData[tid] += sharedData[tid +  1];

    if (tid == 0) blockResults[blockIdx.x] = sharedData[0];
}
```

**6. [10] Na koji način se na grafičkom procesoru sakrivaju kašnjenja koja nastaju prilikom pristupa sporoj, globalnoj memoriji uređaja? Koja razlika tu postoji u odnosu na centralni procesor?**

Na grafičkom procesoru postoji mnogo više procesirajućih elemenata (na primer, reda veličine 3000), što znači da je u idealnom slučaju u svakom trenutku aktivno 3000 niti. U ovom slučaju, sva kašnjenja koja postoje su maskirana paralelizmom svake obrade koja se radi nad podacima.

**7. [15] Napisati jezgro CUDA programa koje vrši obradu nad dvodimenzionalnom kvadratnom matricom realnih brojeva. Jezgro treba da formira novu matricu na osnovu postojeće tako da svaki element novoformirane matrice ima vrednost: Out<sub>x,y</sub> = C1 ∙ In<sub>x,y</sub> + C2 ∙ (In<sub>x-1,y</sub> + In<sub>x+1,y</sub> + In<sub>x,y-1</sub> + In<sub>x,y+1</sub>) / 4 Smatrati da svaki element matrice ima najviše četiri suseda. Smatrati da su matrice alocirane unapred. Koristiti 2D organizaciju jezgra. Prilikom rešavanja zadatka koristiti deljenu memoriju za smeštanje međurezultata i voditi računa da se ostvari maksimalan paralelizam.**

```C
__global__ void filter (float* in, float* out, int n, float C1, float C2) {
    int x = threadIdx.x;
    int y = threadIdx.y;
    int w = blockDim.x;
    int h = blockDim.y;
    float up, down, left, right;
    __shared__ float helper[w][h];
    int real_x = blockIdx.x * w + x;
    int real_y = blockIdx.y * h + y;
    helper[y][x] = in[real_y][real_x];
    __syncthreads();
    
    if (y == 0) {
        if (real_y == 0) up = 1;
        else up = in[real_y - 1][real_x];
    } else {
        up = helper[y - 1][x];
    }
    if (y == h - 1) {
        if (real_y => n) down = 1;
        else down = in[real_y + 1][real_x];
    } else {
        down = helper[y + 1][x];
    }
    if (x == 0) {
        if (real_x == 0) left = 1;
        else left = in[real_y][real_x - 1];
    } else {
        left = helper[y][x - 1];
    }
    if (x == w - 1) {
        if (real_x => n) right = 1;
        else right = in[real_y][real_x + 1];
    } else {
        right = helper[y][x + 1];
    }

    out[real_y][real_x] = C1 * helper[y][x] + C2 * (up + down + left + right) / 4.0;
}
```
